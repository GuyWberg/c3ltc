{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03b99e9",
   "metadata": {},
   "source": [
    "# c3LTC\n",
    "\n",
    "In this notebook, we implement the locally testible code with constant rate, distance and locallity proposed in [Dinur et. al.](https://arxiv.org/abs/2111.04808).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table of contents\n",
    "1. [Representation of Squares and Edges](#representation)\n",
    "2. [Tensor Decoding](#tensor)\n",
    "3. [Parity check generation](#parity)\n",
    "4. [Random generator sets](#sets)\n",
    "5. [c3LTC object](#c3ltc)\n",
    "6. [Concrete Example](#example)\n",
    "7. [Encoding, Decoding and Testing](#tests)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from visualize_c3ltc import *\n",
    "import numpy\n",
    "import random\n",
    "from pyvis import network as net\n",
    "\n",
    "from sage.coding.grs_code import ReedSolomonCode\n",
    "from sage.rings.finite_rings.finite_field_prime_modn import FiniteField_prime_modn as GF\n",
    "from sage.groups.perm_gps.permgroup_named import PSL\n",
    "from sage.matrix.matrix_space import MatrixSpace\n",
    "from sage.coding.linear_code import LinearCode\n",
    "from sage.modules.vector_modn_dense import vector\n",
    "\n",
    "from row_reduce_from_c import row_reduce_and_orthogonal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Representation of Squares and Edges  <a name=\"representation\"></a>\n",
    "\n",
    "Following are classes for describing squares and edges in left-right Cayley graph. Given a group  $G$ and sets $A,B$. \n",
    "\n",
    "$A$-edge is described as $(a,g)$ for $g\\in G, a\\in$, and $B$-edge is described as $(g,b)$ for $g\\in G, b\n",
    "\\in B$. The edge $(a,g)$ represent the edge between the vertices (i.e. group elements) $ag$ and $g$, and the edge $(g,b)$ represents the edge between $gb$ and $g$. Notice that an edge has several equivalent representation: $(a^{-1},ag)$, represents the same edge as $(a,g)$. Initializing ``AEdge(G,a,g)`` with either one of the representation will give an identical edge, e.g. ``AEdge(G,a,g) == AEdge(a^(-1),ag)``. The same holds for $B$-edges respectivley.  \n",
    "\n",
    "A square by a tuple $(a,g,b)$ for $g\\in G, a\\in A, b\\in B$. Similarly to the edges, a squre has several equivalent representations as well: $(a^{-1},ag,b)$, $(a^{-1},agb,b^{-1})$ and $(a,gb,b^{-1})$ all represent the same square. Initializing ``Square(G,a,g,b)`` with either one of the representation will give an identical square, e.g. ``Square(G,a,g,b) == Square(a^(-1),ag,b)``. \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AEdge:\n",
    "    def __init__(self, G, a, g):\n",
    "        edge = self.canonical_a_edge(G, a, g)\n",
    "        self.a = edge[0]\n",
    "        self.g = edge[1]\n",
    "\n",
    "    def canonical_a_edge(self, G, a, g):\n",
    "        element_list = list(G)\n",
    "        index_g = element_list.index(g)\n",
    "        index_ag = element_list.index(a * g)\n",
    "        min_index = min(index_g, index_ag)\n",
    "        if min_index == index_g:\n",
    "            return (a, g)\n",
    "        if min_index == index_ag:\n",
    "            return (a.inverse(), a * g)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AEdge(%s, %s)\" % (self.a, self.g)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, AEdge):\n",
    "            return (self.a == other.a and self.g == other.g)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return (not self.__eq__(other))\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())\n",
    "\n",
    "\n",
    "class BEdge:\n",
    "    def __init__(self, G, g, b):\n",
    "        edge = self.canonical_B_edge(G, g, b)\n",
    "        self.g = edge[0]\n",
    "        self.b = edge[1]\n",
    "\n",
    "    def canonical_B_edge(self, G, g, b):\n",
    "        element_list = list(G)\n",
    "        index_g = element_list.index(g)\n",
    "        index_gb = element_list.index(g * b)\n",
    "        min_index = min(index_g, index_gb)\n",
    "        if min_index == index_g:\n",
    "            return (g, b)\n",
    "        if min_index == index_gb:\n",
    "            return (g * b, b.inverse())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BEdge(%s, %s)\" % (self.g, self.b)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, BEdge):\n",
    "            return (self.g == other.g and self.b == other.b)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return (not self.__eq__(other))\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())\n",
    "\n",
    "\n",
    "class Square:\n",
    "    def __init__(self, G, a, g, b):\n",
    "        square = self.canonical_square(G, a, g, b)\n",
    "        self.a = square[0]\n",
    "        self.g = square[1]\n",
    "        self.b = square[2]\n",
    "\n",
    "    def canonical_square(self, G, a, g, b):\n",
    "        element_list = list(G)\n",
    "        option1 = str((a, g, b))\n",
    "        option2 = str((a.inverse(), a * g, b))\n",
    "        option3 = str((a, g * b, b.inverse()))\n",
    "        option4 = str((a.inverse(), a * g * b, b.inverse()))\n",
    "        minimal = min(option1, option2, option3, option4)\n",
    "        if minimal == option1:\n",
    "            return (a, g, b)\n",
    "        if minimal == option2:\n",
    "            return (a.inverse(), a * g, b)\n",
    "        if minimal == option3:\n",
    "            return (a, g * b, b.inverse())\n",
    "        if minimal == option4:\n",
    "            return (a.inverse(), a * g * b, b.inverse())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Square(%s, %s, %s)\" % (self.a, self.g, self.b)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Square):\n",
    "            return (self.a == other.a and self.b == other.b and self.g == other.g)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return (not self.__eq__(other))\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor Decoding <a name=\"tensor\"></a>\n",
    "\n",
    "Below we implement a simple tensor decoding algorithm. Given a word and two codes $C_A,C_B$, the decoding algorithm for $C_B\\otimes C_A$ first decode all rows with $C_B$, then all columns with $C_A$. This algorithm corrects up to \n",
    "$(d_1d_2-1)/4$ errors. \n",
    "\n",
    "Here, we adopt a slight improvement of this algorithm, instead of decoding all the rows and then all the columns, we keep two sets called ``iterating_set_code_a`` and ``iterating_set_code_b``. Upon a correction of row $i$ (related to code $C_B$), each entry that was change signifies a column that needs to be checked (as it might not be in the code due to the change). Thus we'll add this column to ``iterating_set_code_b``. Iterating over ``iterating_set_code_b``, we do the same and update ``iterating_set_code_a``. \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tensor_decoding(tensor_word, C_A: LinearCode, C_B: LinearCode):\n",
    "    \"\"\" Returns a decoded word in tensor code. \n",
    "\n",
    "    Keyword arguments:\n",
    "    tensor_word -- matrix of length(C_A) x length(C_B).\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    \"\"\"\n",
    "\n",
    "    n_a = len(C_A.parity_check_matrix().columns())\n",
    "    n_b = len(C_B.parity_check_matrix().columns())\n",
    "    field = C_A.base_field()\n",
    "\n",
    "    def tensor_word_to_tuple(m):\n",
    "        return tuple(m.reshape((n_a * n_b)))\n",
    "\n",
    "    corrected_word = numpy.copy(tensor_word)\n",
    "    iterating_set_C_B = [i for i in range(n_a)]\n",
    "    iterating_set_C_A = [i for i in range(n_b)]\n",
    "    past_words = []\n",
    "    word_to_tuple = tensor_word_to_tuple(corrected_word)\n",
    "    while (len(iterating_set_C_A) != 0 or len(iterating_set_C_B) != 0) and word_to_tuple not in past_words:\n",
    "        past_words.append(word_to_tuple)\n",
    "\n",
    "        new_iterating_C_A = []\n",
    "        new_iterating_C_B = []\n",
    "        for i in iterating_set_C_B:\n",
    "            local_word = vector(field, corrected_word[i, :])\n",
    "            try:\n",
    "                corrected_locally = C_B.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_C_B.append(i)\n",
    "                continue\n",
    "            for j in range(n_b):\n",
    "                if local_word[j] != corrected_locally[j]:\n",
    "                    new_iterating_C_A.append(j)\n",
    "                corrected_word[i][j] = corrected_locally[j]\n",
    "        for j in iterating_set_C_A:\n",
    "            local_word = vector(field, corrected_word[:, j])\n",
    "            try:\n",
    "                corrected_locally = C_A.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_C_A.append(j)\n",
    "                continue\n",
    "            for i in range(n_a):\n",
    "                if local_word[i] != corrected_locally[i]:\n",
    "                    new_iterating_C_B.append(i)\n",
    "                corrected_word[i][j] = corrected_locally[i]\n",
    "        iterating_set_C_A = set(new_iterating_C_A)\n",
    "        iterating_set_C_B = set(new_iterating_C_B)\n",
    "        word_to_tuple = tensor_word_to_tuple(corrected_word)\n",
    "    return corrected_word\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parity check generation <a name=\"parity\"></a>\n",
    "\n",
    "The following function reterns a representation of the parity check matrix of $c^3LTC$ code. It gets a group $G$, two sets $A,B$ and two codes $C_A,C_B$, such that $n_A = |A|, n_B = |B|$ and $C_A,C_B$ are defined on the same field. \n",
    "\n",
    "The function proceeds in two stages:\n",
    "1. In the first stage, it collects the edges (by $A,B$) into sets.\n",
    "2. In the seocnd stage, the local constraint on each edge are injected according to the squares.\n",
    "    - Each edges \"sees\" a tuple of values squares such that the values on those squares \n",
    "      should be contained in either $C_A$ or $C_B$ (depending on whether it's an $A$-edge or $B$-edge).\n",
    "    - To enforce the condition above, each one of these squares is associated with a column from the\n",
    "      parity check of the local code ($C_A$ or $C_B$). The squares indicate the specific squares that\n",
    "      participate in the constraints on that edge. \n",
    "    - The dictionary (mapping) ''constraints'' in the code, holds a sparse representation of the constraints\n",
    "      in the parity check induced by the input parameters. It maps a square object (that indicates a column) \n",
    "      to a dictionary whose keys are row numbers and the values are the values in the large parity check matrix. \n",
    "    - In other words, a copy of the local parity check is being injected into the squares-parity-check\n",
    "      such that each column of the small parity check is placed into the column associated with different square\n",
    "      (according to the squares specified by the row). \n",
    "      \n",
    "The function returns a sparse representation of the parity check. It returns a dictionary (mapping) with ``Square`` elements as keys. Each square is mapped to a sparse representation of the corresponding column to this square in the parity check matrix. Namley, it contains a mapping from row number to value. Hence non zero values in the parity check matrix are specified first by their ``Square``, then by their row, and finally by their value.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def embedding_local_parity_constraints_on_squares(C_A, C_B, G, A, B):\n",
    "    \"\"\" Returns\n",
    "    1) Sparse representation of the constrsints by a mapping of squares (represeted by 3 group elements (a,g,b))\n",
    "        to dictionary whose keys are rows in which the square has non zero value, and value is the value in the relevant row and column.\n",
    "    2) Number constraints of rows in the constraint matrix.\n",
    "\n",
    "    Keyword arguments:\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    G -- Sage group object.\n",
    "    A -- list of group elements.\n",
    "    B -- list of group elements.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    constraints = {}\n",
    "    row = 0\n",
    "    parity_A = C_A.parity_check_matrix()\n",
    "    parity_B = C_B.parity_check_matrix()\n",
    "    codim_C_A = len(parity_A.rows())\n",
    "    codim_C_B = len(parity_B.rows())\n",
    "\n",
    "    # Stage 1 - collecting the edges\n",
    "    edges_A = set()\n",
    "    edges_B = set()\n",
    "    for g in G:\n",
    "        for a in A:\n",
    "            edges_A.add(AEdge(G, a, g))\n",
    "        for b in B:\n",
    "            edges_B.add(BEdge(G, g, b))\n",
    "\n",
    "    assert len(edges_A) == len(list(G)) * len(A) / 2\n",
    "    assert len(edges_B) == len(list(G)) * len(B) / 2\n",
    "\n",
    "    # Stage 2 - iterating over edges and \"injecting\" constraints into squares\n",
    "    for e in edges_A:\n",
    "        a = e.a\n",
    "        g = e.g\n",
    "        for (j, b) in enumerate(B):  # B[j] = b\n",
    "            square = Square(G, a, g, b)\n",
    "            if square not in constraints:  # if no contraints were added on this square before\n",
    "                constraints[square] = {}\n",
    "            for (k, v) in enumerate(parity_A[:, j]):  # parity_A[k,j] = v\n",
    "                constraints[square][row + k] = v[0]  # v is represted as a length 1 array\n",
    "        row += codim_C_A\n",
    "\n",
    "    for e in edges_B:\n",
    "        g = e.g\n",
    "        b = e.b\n",
    "        for (i, a) in enumerate(A):  # A[i] = a\n",
    "            square = Square(G, a, g, b)\n",
    "            if square not in constraints:  # if no contraints were added on this square before\n",
    "                constraints[square] = {}\n",
    "            for (k, v) in enumerate(parity_B[:, i]):  # parity_B[k,i] = v\n",
    "                constraints[square][row + k] = v[0]  # v is represted as a length 1 array\n",
    "        row += codim_C_B\n",
    "\n",
    "    assert len(constraints) == len(A) * len(B) * len(list(G)) / 4\n",
    "    assert row == codim_C_A * len(edges_A) + codim_C_B * len(edges_B)\n",
    "\n",
    "    return (constraints, row, edges_A, edges_B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random generator sets <a name=\"sets\"></a>\n",
    "\n",
    "The following functions gets a group $G$, and two numbers, representing the size of two desired sets of generators. The number of elements of order 2 and of non order 2 are treated separatly (see the second and third argument to ``random_generators``).\n",
    "\n",
    "The function ``get_AB_with_TNC`` returns two sets $A,B$ that satisfies the total no-conjugacy:\n",
    "$$\n",
    "\\forall a\\in A, b\\in B, g\\in G, \\ g^{-1}ag\\ne b\n",
    "$$\n",
    "It searches for these sets for in a brute-force way for several trials and exists if no such pair was found. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_generators(G, n, n_order_2=0):\n",
    "    \"\"\" Returns an inverse closed set of n + n_order_2 elements from G.\n",
    "\n",
    "\n",
    "    Keyword arguments:\n",
    "    G -- Sage group object.\n",
    "    n -- number.\n",
    "    n_order_2 -- number of elements of order 2. \n",
    "    \n",
    "    Note:\n",
    "    1) n has to be smaller than the number of elements in G.\n",
    "    \"\"\"\n",
    "\n",
    "    list_G = list(G)\n",
    "    assert n < len(list_G)\n",
    "    gens = []\n",
    "    # non order 2 generators\n",
    "    i = 0\n",
    "    while i < n / 2:\n",
    "        c = random.choice(list_G)\n",
    "        if c not in gens and c * c != G.identity():\n",
    "            gens.append(c)\n",
    "            gens.append(c.inverse())\n",
    "            i += 1\n",
    "    # order 2 generators\n",
    "    i = 0\n",
    "    while i < n_order_2:\n",
    "        c = random.choice(list_G)\n",
    "        if c not in gens and c * c == G.identity():\n",
    "            gens.append(c)\n",
    "            i += 1    \n",
    "    return gens\n",
    "\n",
    "def get_AB_with_TNC(G, n, n_order_2 = 0, trials = 100):\n",
    "    \"\"\" Returns two sets of a group G of size n, for which that TNC condition hold.\n",
    "        If no sets were found after # of trials, it exits with error.  \n",
    "\n",
    "\n",
    "    Keyword arguments:\n",
    "    G -- Sage group object.\n",
    "    n -- number.\n",
    "    n_order_2 -- number. \n",
    "    trials -- number of trials to find A,B that uphold TNC. \n",
    "    \n",
    "    Note:\n",
    "    1) size has to be smaller than the number of elements in G.\n",
    "    \"\"\"\n",
    "    \n",
    "    for _ in range(trials):\n",
    "        A = random_generators(G,n,n_order_2)\n",
    "        B = random_generators(G,n,n_order_2)\n",
    "        violations = 0\n",
    "        for a in A:\n",
    "            for b in B:\n",
    "                for g in G:\n",
    "                    if a * g == g * b:\n",
    "                        violations += 1\n",
    "                        break\n",
    "        if violations == 0:\n",
    "            return A, B\n",
    "    exit(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoding c3LTC <a name=\"decoding\"></a>\n",
    "\n",
    "The decoding function ``decode_via_edges`` and ``decode_via_vertices`` decode a word $w$. These functions different from the decoding algorithm presented in the original paper, and are conceptually similar to tensor decoding algorithm and expander code decoding. \n",
    "Similarly to algorithms for decoding in expander codes, ``decode_via_vertices`` decodes a word by locally correcting the local views of ''unsatisfied'' vertices (i.e., vertices whose local view is not a leagal tensor codeword). Similarly to decoding in tensor codes, ``decode_via_edges`` decodes the local view of ''unsatisfied'' edges (i.e., edges whose local view is not a leagal codeword in $C_A$ or $C_B$, depending on their type), and alternate between decoding all such ``AEdges`` followed by decoding of all ``BEdges`` (akin to the alternation between rows and columns in tensor decoding). "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def decode_via_edges(c3ltc, noisy_word):\n",
    "    squares_to_values = {}\n",
    "    for (i, v) in enumerate(noisy_word):\n",
    "        squares_to_values[c3ltc.index_to_square[i]] = v\n",
    "    init = True\n",
    "    iterating_set_A = None\n",
    "    iterating_set_B = None\n",
    "    past_words = []\n",
    "    word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "    while (init or (\n",
    "            len(iterating_set_A) != 0 or len(iterating_set_B) != 0)) and word_from_square_values not in past_words:\n",
    "        past_words.append(word_from_square_values)\n",
    "        if init:\n",
    "            init = False\n",
    "            iterating_set_A = set(c3ltc.edges_A)\n",
    "            iterating_set_B = set(c3ltc.edges_B)\n",
    "        new_iterating_set_A = set([])\n",
    "        new_iterating_set_B = set([])\n",
    "\n",
    "        for k,e in enumerate(iterating_set_A):\n",
    "            a = e.a\n",
    "            g = e.g\n",
    "            i = c3ltc.A.index(a)\n",
    "            local_word = vector(c3ltc.base_field, [0] * len(c3ltc.B))\n",
    "            for (j, b) in enumerate(c3ltc.B):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                local_word[j] = squares_to_values[square]\n",
    "            try:\n",
    "                corrected_localy = c3ltc.C_B.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_set_A.add(AEdge(c3ltc.G, a, g))\n",
    "                continue\n",
    "            for (j, b) in enumerate(c3ltc.B):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                if squares_to_values[square] != corrected_localy[j]:\n",
    "                    new_iterating_set_A.add(AEdge(c3ltc.G, a, g * b))\n",
    "                    new_iterating_set_B.add(BEdge(c3ltc.G, g, b))\n",
    "                    new_iterating_set_B.add(BEdge(c3ltc.G, a * g, b))\n",
    "                squares_to_values[square] = corrected_localy[j]\n",
    "            if e in new_iterating_set_A:\n",
    "                new_iterating_set_A.remove(e)\n",
    "\n",
    "        for k,e in enumerate(iterating_set_B):\n",
    "            g = e.g\n",
    "            b = e.b\n",
    "            j = c3ltc.B.index(b)\n",
    "            local_word = vector(c3ltc.base_field, [0] * len(c3ltc.A))\n",
    "            for (i, a) in enumerate(c3ltc.A):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                local_word[i] = squares_to_values[square]\n",
    "            try:\n",
    "                corrected_localy = c3ltc.C_A.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_set_B.add(BEdge(c3ltc.G, g, b))\n",
    "                continue\n",
    "            for (i, a) in enumerate(c3ltc.A):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                if squares_to_values[square] != corrected_localy[i]:\n",
    "                    new_iterating_set_B.add(BEdge(c3ltc.G, a * g, b))\n",
    "                    new_iterating_set_A.add(AEdge(c3ltc.G, a, g))\n",
    "                    new_iterating_set_A.add(AEdge(c3ltc.G, a, g * b))\n",
    "                squares_to_values[square] = corrected_localy[i]\n",
    "            if e in new_iterating_set_B:\n",
    "                new_iterating_set_B.remove(e)\n",
    "\n",
    "        iterating_set_A = new_iterating_set_A\n",
    "        iterating_set_B = new_iterating_set_B\n",
    "        word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "    return word_from_square_values\n",
    "\n",
    "def decode_via_vertices(c3ltc, noisy_word):\n",
    "    n_a = len(c3ltc.C_A.parity_check_matrix().columns())\n",
    "    n_b = len(c3ltc.C_B.parity_check_matrix().columns())\n",
    "    M = MatrixSpace(c3ltc.base_field, n_a, n_b)\n",
    "    squares_to_values = {}\n",
    "    for (i, v) in enumerate(noisy_word):\n",
    "        squares_to_values[c3ltc.index_to_square[i]] = v\n",
    "    init = True\n",
    "    iterating_set = None\n",
    "    past_words = []\n",
    "    word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "\n",
    "    while (init or len(iterating_set)) != 0 and word_from_square_values not in past_words:\n",
    "        past_words.append(word_from_square_values)\n",
    "        if init:\n",
    "            init = False\n",
    "            iterating_set = set(c3ltc.G)\n",
    "        new_iterating_set = set([])\n",
    "        for g in iterating_set:\n",
    "            local_view = numpy.zeros((n_a, n_b))\n",
    "            for i, a in enumerate(c3ltc.A):\n",
    "                for j, b in enumerate(c3ltc.B):\n",
    "                    square = Square(c3ltc.G,a, g, b)\n",
    "                    local_view[i][j] = squares_to_values[square]\n",
    "            try:\n",
    "                corrected_local_view = tensor_decoding(M(local_view), c3ltc.C_A, c3ltc.C_B)\n",
    "            except:\n",
    "                new_iterating_set.append(g)\n",
    "                continue\n",
    "            for i, a in enumerate(c3ltc.A):\n",
    "                for j, b in enumerate(c3ltc.B):\n",
    "                    square = Square(c3ltc.G,a, g, b)\n",
    "                    if corrected_local_view[i][j] != local_view[i][j]:\n",
    "                        new_iterating_set.add(a * g)\n",
    "                        new_iterating_set.add(g * b)\n",
    "                        new_iterating_set.add(a * g * b)\n",
    "                    squares_to_values[square] = corrected_local_view[i][j]\n",
    "            if g in new_iterating_set:\n",
    "                new_iterating_set.remove(g)\n",
    "        iterating_set = new_iterating_set\n",
    "        word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "\n",
    "    return word_from_square_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# c3LTC object <a name=\"c3ltc\"></a>\n",
    "\n",
    "The class ``c3LTC`` generates an object of the new code. It receives two codes, $C_A,C_B$ a group $G$ and two generator sets $A,B$. The code generates parity check and generator matrices using the function ``embedding_local_parity_constraints_on_squares``. It also uses the library [spasm](https://github.com/cbouilla/spasm). to perform linear algebra functions, for performance improvements. \n",
    "\n",
    "The function ``local_codeword_on_vertex`` gets as input a word $w$ (possibly noisy) and a vertex $v$. It returns $w|_{X(v)}$, the restriction of $w$ to the squares $v$ sees in his local tensor-word view. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class c3LTC:\n",
    "\n",
    "    def __init__(self, C_A, C_B, G, A, B):\n",
    "        assert len(C_A.generator_matrix().columns()) == len(A)\n",
    "        assert len(C_B.generator_matrix().columns()) == len(B)\n",
    "        assert C_A.base_field().characteristic() == C_B.base_field().characteristic()\n",
    "\n",
    "        (sparse_constraints, count, self.edges_A, self.edges_B) = embedding_local_parity_constraints_on_squares(C_A, C_B, G, A, B)\n",
    "\n",
    "        # process sparse constraints\n",
    "\n",
    "        parity_checks = numpy.zeros((count, len(sparse_constraints)))\n",
    "        for (i, l) in enumerate(sparse_constraints):\n",
    "            for k in sparse_constraints[l]:\n",
    "                parity_checks[k][i] = sparse_constraints[l][k]\n",
    "\n",
    "        # additional mappings\n",
    "\n",
    "        self.square_to_index = {}\n",
    "        self.index_to_square = {}\n",
    "        self.squares = list(sparse_constraints)\n",
    "        self.vertex_to_squares = {}\n",
    "        self.vertex_to_neighbours_A = {}\n",
    "        self.vertex_to_neighbours_B = {}\n",
    "        self.square_to_vertices = {}\n",
    "        self.n_vertices = len(list(G))\n",
    "\n",
    "        list_G = list(G)\n",
    "\n",
    "        for (i, l) in enumerate(self.squares):\n",
    "            self.square_to_index[l] = i\n",
    "            self.index_to_square[i] = l\n",
    "        \n",
    "        \n",
    "        for g in G:\n",
    "            view = numpy.zeros((len(A), len(B)))\n",
    "            for (i, a) in enumerate(A):\n",
    "                for (j, b) in enumerate(B):\n",
    "                    view[i][j] = self.squares.index(Square(G,a, g, b))\n",
    "            self.vertex_to_squares[list_G.index(g)] = view\n",
    "\n",
    "        for g in G:\n",
    "            view = []\n",
    "            for (i, a) in enumerate(A):\n",
    "                view.append(list_G.index(a * g))\n",
    "            self.vertex_to_neighbours_A[list_G.index(g)] = view\n",
    "        \n",
    "        for g in G:\n",
    "            view = []\n",
    "            for (j, b) in enumerate(B):\n",
    "                view.append(list_G.index(g * b))\n",
    "            self.vertex_to_neighbours_B[list_G.index(g)] = view\n",
    "        \n",
    "        for (i, s) in enumerate(self.squares):\n",
    "            view = []\n",
    "            a = s.a\n",
    "            g = s.g\n",
    "            b = s.b\n",
    "            view.append(int(list_G.index(a * g)))\n",
    "            view.append(int(list_G.index(g * b)))\n",
    "            view.append(int(list_G.index(a * g * b)))\n",
    "            view.append(int(list_G.index(g * b)))\n",
    "            self.square_to_vertices[i] = view\n",
    "\n",
    "        # properties of the code\n",
    "\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.C_A = C_A\n",
    "        self.C_B = C_B\n",
    "        self.G = G\n",
    "        self.base_field = C_A.base_field()\n",
    "        gen, par = row_reduce_and_orthogonal(sparse_constraints, C_A.base_field().characteristic(), count,len(sparse_constraints))\n",
    "        M = MatrixSpace(self.base_field, gen.shape[0],\n",
    "                        gen.shape[1])\n",
    "        self.generator_matrix = M(gen)\n",
    "        M = MatrixSpace(self.base_field, par.shape[0],\n",
    "                        par.shape[1])\n",
    "        self.parity_check_matrix = M(par)\n",
    "        self.length = numpy.array(self.generator_matrix).shape[1]\n",
    "        self.dimension = numpy.array(self.generator_matrix).shape[0]\n",
    "\n",
    "    def square_to_value_to_word(self, squares_to_values):\n",
    "        corrected_word = vector(self.base_field, [0] * len(squares_to_values))\n",
    "        for square in self.square_to_index:\n",
    "            corrected_word[self.square_to_index[square]] = squares_to_values[square]\n",
    "        return corrected_word\n",
    "\n",
    "    def syndrome(self, c):\n",
    "        return self.parity_check_matrix * c\n",
    "    \n",
    "    def decode_via_edges(self, noisy_word):\n",
    "        return decode_via_edges(self, noisy_word)\n",
    "    \n",
    "    def decode_via_vertices(self, noisy_word):\n",
    "        return decode_via_vertices(self, noisy_word)\n",
    "\n",
    "    def local_codeword_on_vertex(self, vertex, word):\n",
    "        labels_view = self.vertex_to_squares[vertex]\n",
    "        rows = len(labels_view)\n",
    "        cols = len(labels_view[0])\n",
    "        local_view_values = numpy.array([0] * rows\n",
    "                                        * cols).reshape((rows, cols))\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                local_view_values[i][j] = int(word[int(self.vertex_to_squares[vertex][i][j])])\n",
    "        return local_view_values\n",
    "\n",
    "    def __repr__(self):\n",
    "        rep = 'c3LTC'\n",
    "        return rep\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concrete Example <a name=\"example\"></a>\n",
    "\n",
    "Below is a concrete example for a construction of the new code with the following parameters:\n",
    "\n",
    "- $G = PSL_2(11)$. \n",
    "- $C_A,C_B = RS[10,6]$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G = PSL(2,7)\n",
    "A, B = get_AB_with_TNC(G, 6)\n",
    "C_A = ReedSolomonCode(GF(7), Integer(6), Integer(4))\n",
    "C_B = ReedSolomonCode(GF(7), Integer(6), Integer(4))\n",
    "c3ltc = c3LTC(C_A, C_B, G, A,B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = net.Network(notebook=True)\n",
    "g.toggle_physics(False)\n",
    "g.from_nx(show_graph(c3ltc))\n",
    "g.show('graph.html')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vertices that participate in square no. 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_square(c3ltc,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Squares lables of the local view of vertex 1. \n",
    "\n",
    "The columns (in red) are considerd \"right\" neighbours (i.e., the indices of the vertices $gb$ for $b\\in B$), and the rows (in blue) are considered (i.e., the indices of the vertices $ ag$ for $a\\in A$) neighbours. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "local_view(c3ltc,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shows the squares lables of the local view of vertex 1 and 2 (the common row is highlighted). \n",
    "\n",
    "The generating sets $A,B$ of the Cayley graph is ordered like: $(g_1,g_1^{-1}, g_2,g_2^{-1}...)$. That is, the generators are ordered in pairs of generator followed by its inverse. \n",
    "\n",
    "Therefore, if vertex 2 is the first neighbour by the first generator in vertex 1, then in vertex 2, the second neighbour is going to be vertex 1. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_common(c3ltc, 1, c3ltc.vertex_to_neighbours_A[1][0], \"A\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoding, Decoding and Testing <a name=\"tests\"></a>\n",
    "\n",
    "Below we provide several functions for encoding, decoding, and testing the properties of the generated code, as well as some supllementry functions. \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def word_with_k_injected_local_views(c3ltc, k):\n",
    "    \"\"\" Create a random word with k local views \"injected\" with random tensor codewords. \n",
    "        Note that some vertices may not have a tensor codeword in their local view because the \n",
    "        function writes over pre-existing values. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    k -- number. \n",
    "    \"\"\"\n",
    "    word = vector(c3ltc.base_field, [0] * c3ltc.length)\n",
    "    for _ in range(k):\n",
    "        v = random.randint(0,len(c3ltc.G)-1)\n",
    "        local_view_flat = c3ltc.vertex_to_squares[v].reshape((C_A.length() * C_B.length()))\n",
    "        random_local_word = random_tensor_word(c3ltc.C_A, c3ltc.C_B)\n",
    "        for (i,b) in enumerate(random_local_word):\n",
    "            word[int(local_view_flat[i])] = Integer(b)\n",
    "    return word\n",
    "\n",
    "def is_word_in_tensor_code(C_A,C_B, word):\n",
    "    \"\"\" Checks if a matrix tensor word is in code by verifying that each row and column are \n",
    "        in the associated code. \n",
    "\n",
    "    Keyword arguments:\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    word -- number. \n",
    "    \"\"\"\n",
    "    rows = word.shape[0]\n",
    "    cols = word.shape[1]\n",
    "    field = C_A.base_field()\n",
    "    for i in range(rows):\n",
    "        row = word[i,:]\n",
    "        if 0 != numpy.count_nonzero(C_A.syndrome(vector(field, row))):\n",
    "            return false\n",
    "    for i in range(cols):\n",
    "        col = word[:,i]\n",
    "        if 0 != numpy.count_nonzero(C_B.syndrome(vector(field, col))):\n",
    "            return false\n",
    "    return true\n",
    "\n",
    "def unsatisfied_vertices(c3ltc, word):\n",
    "    \"\"\" Returns a list of vertices for which the local view in the given word is not in the\n",
    "        tensor code. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    word -- number. \n",
    "    \"\"\"\n",
    "    n_vertices = len(c3ltc.G)\n",
    "    unsat = []\n",
    "    for g in range(n_vertices):\n",
    "        lv = c3ltc.local_codeword_on_vertex(g, word)\n",
    "        if not is_word_in_tensor_code(c3ltc.C_A,c3ltc.C_B, lv):\n",
    "            unsat.append(g)\n",
    "    return unsat\n",
    "\n",
    "\n",
    "def estimate_ltc_constant_with_injected_local_views(c3ltc, trials = 10, max_injected = 50):\n",
    "    \"\"\" Returns an estimation of the local testability parameter by sampling a random noisy word and counting the \n",
    "        relative fraction of unsatisfied vertices. \n",
    "        The noise is generated by injecting random tensor words into the local view of vertices. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    trials -- number. \n",
    "    max_injected -- number. \n",
    "    \"\"\"\n",
    "    c = Infinity\n",
    "    n_vertices = len(c3ltc.G)\n",
    "    for _ in range(trials):\n",
    "        word = word_with_k_injected_local_views(c3ltc, max_injected)\n",
    "        syndrome_weight = float(\n",
    "            len(unsatisfied_vertices(c3ltc,word)) / n_vertices\n",
    "        )\n",
    "        error_weight = float(numpy.count_nonzero(word)/ c3ltc.length)\n",
    "        if error_weight != 0:\n",
    "            c = min(c, float(syndrome_weight / error_weight))\n",
    "    return c\n",
    "\n",
    "def estimate_ltc_constant_with_random_local_views(c3ltc, trials = 10, max_injected = 50, sparsity = 2):\n",
    "    \"\"\" Returns an estimation of the local testability parameter by sampling a random noisy word and counting the \n",
    "        relative fraction of unsatisfied vertices. \n",
    "        The noise is sampled randomly by the se. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    trials -- number. \n",
    "    max_injected -- number. \n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    c = Infinity\n",
    "    n_vertices = len(c3ltc.G)\n",
    "    for _ in range(trials):\n",
    "        noisy_word, word = random_noisy_word(c3ltc, sparsity)\n",
    "        syndrome_weight = float(\n",
    "            len(unsatisfied_vertices(c3ltc,noisy_word)) / n_vertices\n",
    "        )\n",
    "        error_weight = float(numpy.count_nonzero(word - noisy_word)/ c3ltc.length)\n",
    "        if error_weight != 0:\n",
    "            c = min(c, float(syndrome_weight / error_weight))\n",
    "    return c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions for random samplings (used in the functions above)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_vector(size, max_val, sparsity = 2):\n",
    "    \"\"\" Retruns a random vector of a specified size, each entry sampled in the range between \n",
    "        0 and max_val. Sparsity reflects that a non-zero probability is sampled.\n",
    "        The probability of a non-zero element to appear in the array is 1/(max_val - 1) * (1/2) ^ sparsity.\n",
    "\n",
    "    Keyword arguments:\n",
    "    size -- number.\n",
    "    max_val -- number.\n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    return [random.randint(0,max_val)*numpy.random.binomial(1, pow(0.5,sparsity), 1)[0] for _ in range(size)]\n",
    "\n",
    "def random_tensor_word(C_A, C_B):\n",
    "    \"\"\" Retruns a random tensor codeword. It is achieved by sampling a random vector, multiplying\n",
    "        it by the tensor of the generators matrices of C_A, C_B.\n",
    "        The word returned is a flattening of the \"matrix\" view of the tensor codeword into a\n",
    "        single vector by concatenating the rows of the respective matrix.\n",
    "        Sparsity parameter is defined in the random_vector function. \n",
    "\n",
    "    Keyword arguments:\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    field_char = C_A.base_field().characteristic()\n",
    "    tensor_dimension = C_A.dimension() * C_B.dimension()\n",
    "    rv = random_vector(tensor_dimension,field_char,0)\n",
    "    message = vector(C_A.base_field(), rv)\n",
    "    return (C_A.generator_matrix().tensor_product(C_B.generator_matrix()).transpose() * message)\n",
    "\n",
    "def random_noisy_word(c3ltc, sparsity = 2):\n",
    "    \"\"\" Retruns a noisy c3ltc codeword by encoding a random vector. \n",
    "    Sparsity parameter is defined in the random_vector function. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    field = c3ltc.base_field\n",
    "    error = vector(field, random_vector(c3ltc.length, field.characteristic(),sparsity))\n",
    "    word = vector(field, random_word(c3ltc)) \n",
    "    return vector(field, word + error), vector(field, word)\n",
    "\n",
    "def random_word(c3ltc):\n",
    "    \"\"\" Retruns a c3ltc codeword by encoding a random vector. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    \"\"\"\n",
    "    field = c3ltc.base_field\n",
    "    rv = random_vector(c3ltc.dimension,field.characteristic(),0)\n",
    "    message = c3ltc.generator_matrix.transpose() * vector(field, rv)    \n",
    "    return message\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we test the decoding algorithms on a noisy codeword, generated by adding random noise a codeword. First, we employe decoding along the edges, then decoding along the vertices. After each run, we print if the decoding was succesful. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noisy_word, word = random_noisy_word(c3ltc,2)\n",
    "corrected = c3ltc.decode_via_edges(noisy_word)\n",
    "corrected == word\n",
    "print(\"Decoded correctly by edges?\", corrected == word)\n",
    "corrected = c3ltc.decode_via_vertices(word)\n",
    "print(\"Decoded correctly by vertices?\", corrected == word)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we show the local view of a vertex. Above, the local view presented was the labels of the squares that participate in the vertex's local view. Here, given a concrete (possibly noisy) word, we present the local values assigned to the squares. Hovering on a square value shows the label of that square. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "local_view_in_word(c3ltc,word,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_common_views_in_word(c3ltc,word,1,c3ltc.vertex_to_neighbours_A[1][0],\"A\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_common_views_in_word(c3ltc,word,1,c3ltc.vertex_to_neighbours_A[1][0],\"A\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a visualization that displays the unsatisfied vertices (for which the local view is not a legal tensor codeword). "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noisy_word, word = random_noisy_word(c3ltc,4)\n",
    "print(\"Dintance of noisy word:\", numpy.count_nonzero(noisy_word-word), \"/\",c3ltc.length, \"(\"+str(numpy.count_nonzero(noisy_word-word) / c3ltc.length * 100) + \"%)\")\n",
    "g = net.Network(notebook=True)\n",
    "g.toggle_physics(False)\n",
    "g.from_nx(show_graph(c3ltc, unsatisfied_vertices(c3ltc, noisy_word)))\n",
    "g.show('graph.html')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we print a heuristic estimation of the generated code. See the functions ``estimate_ltc_constant_with_injected_local_views`` and ``estimate_ltc_constant_with_random_local_views``. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"LTC constant, structured noise\", estimate_ltc_constant_with_injected_local_views(c3ltc))\n",
    "print(\"LTC constant, random noise\", estimate_ltc_constant_with_random_local_views(c3ltc, sparsity = 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff8813bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTC constant, structured noise 1.5711206896551726\n",
      "LTC constant, random noise 1.303448275862069\n"
     ]
    }
   ],
   "source": [
    "print(\"LTC constant, structured noise\", estimate_ltc_constant_with_injected_local_views(c3ltc))\n",
    "print(\"LTC constant, random noise\", estimate_ltc_constant_with_random_local_views(c3ltc, sparsity = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c032494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.6",
   "language": "sage",
   "name": "sagemath-9.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
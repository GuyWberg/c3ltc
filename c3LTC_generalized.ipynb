{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373d73be",
   "metadata": {},
   "source": [
    "# c3LTC\n",
    "\n",
    "In this notebook, we implement the locally testible code with constant rate, distance and locallity proposed in [Dinur et. al.](https://arxiv.org/abs/2111.04808).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aba628",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Table of contents\n",
    "1. [Representation of Squares and Edges](#representation)\n",
    "2. [Tensor Decoding](#tensor)\n",
    "3. [Parity check generation](#parity)\n",
    "4. [Random generator sets](#sets)\n",
    "5. [c3LTC object](#c3ltc)\n",
    "6. [Concrete Example](#example)\n",
    "7. [Encoding, Decoding and Testing](#tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09ffcdf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.visualize_c3ltc import *\n",
    "import numpy\n",
    "import random\n",
    "from pyvis import network as net\n",
    "from sage.coding.grs_code import ReedSolomonCode\n",
    "from sage.matrix.matrix_space import MatrixSpace\n",
    "from sage.coding.linear_code import LinearCode\n",
    "from sage.groups.matrix_gps.matrix_group import *\n",
    "\n",
    "from src.row_reduce_from_c import row_reduce_and_orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc5ab4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Representation of Squares and Edges  <a name=\"representation\"></a>\n",
    "\n",
    "Following are classes for describing squares and edges in left-right Cayley graph. Given a group  $G$ and sets $A,B$. \n",
    "\n",
    "$A$-edge is described as $(a,g)$ for $g\\in G, a\\in A$, and $B$-edge is described as $(g,b)$ for $g\\in G, b\n",
    "\\in B$. The edge $(a,g)$ represent the edge between the vertices (i.e. group elements) $ag$ and $g$, and the edge $(g,b)$ represents the edge between $gb$ and $g$. Notice that an edge has several equivalent representation: $(a^{-1},ag)$, represents the same edge as $(a,g)$. Initializing ``AEdge(G,a,g)`` with either one of the representation will give an identical edge, e.g. ``AEdge(G,a,g) == AEdge(a^(-1),ag)``. The same holds for $B$-edges respectivley.  \n",
    "\n",
    "A square by a tuple $(a,g,b)$ for $g\\in G, a\\in A, b\\in B$. Similarly to the edges, a squre has several equivalent representations as well: $(a^{-1},ag,b)$, $(a^{-1},agb,b^{-1})$ and $(a,gb,b^{-1})$ all represent the same square. Initializing ``Square(G,a,g,b)`` with either one of the representation will give an identical square, e.g. ``Square(G,a,g,b) == Square(G, a^(-1),ag,b)``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617d3baf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AEdge:\n",
    "    def __init__(self, G, a, g):\n",
    "        edge = self.canonical_a_edge(G, a, g)\n",
    "        self.a = edge[0]\n",
    "        self.g = edge[1]\n",
    "\n",
    "    def canonical_a_edge(self, G, a, g):\n",
    "        element_list = list(G)\n",
    "        index_g = element_list.index(g)\n",
    "        index_ag = element_list.index(G.op(a,g))\n",
    "        min_index = min(index_g, index_ag)\n",
    "        if min_index == index_g:\n",
    "            return (a, g)\n",
    "        if min_index == index_ag:\n",
    "            return (a.inverse(), G.op(a,g))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AEdge(%s, %s)\" % (self.a, self.g)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, AEdge):\n",
    "            return (self.a == other.a and self.g == other.g)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return (not self.__eq__(other))\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())\n",
    "\n",
    "\n",
    "class BEdge:\n",
    "    def __init__(self, G, g, b):\n",
    "        edge = self.canonical_B_edge(G, g, b)\n",
    "        self.g = edge[0]\n",
    "        self.b = edge[1]\n",
    "\n",
    "    def canonical_B_edge(self, G, g, b):\n",
    "        element_list = list(G)\n",
    "        index_g = element_list.index(g)\n",
    "        index_gb = element_list.index(G.op(g,b))\n",
    "        min_index = min(index_g, index_gb)\n",
    "        if min_index == index_g:\n",
    "            return (g, b)\n",
    "        if min_index == index_gb:\n",
    "            return (G.op(g,b), b.inverse())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BEdge(%s, %s)\" % (self.g, self.b)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, BEdge):\n",
    "            return (self.g == other.g and self.b == other.b)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return (not self.__eq__(other))\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())\n",
    "\n",
    "\n",
    "class Square:\n",
    "    def __init__(self, G, a, g, b):\n",
    "        square = self.canonical_square(G, a, g, b)\n",
    "        self.a = square[0]\n",
    "        self.g = square[1]\n",
    "        self.b = square[2]\n",
    "\n",
    "    def canonical_square(self, G, a, g, b):\n",
    "        element_list = list(G)\n",
    "        option1 = str((a, g, b))\n",
    "        option2 = str((a.inverse(), G.op(a,g), b))\n",
    "        option3 = str((a, G.op(g,b), b.inverse()))\n",
    "        option4 = str((a.inverse(), G.op(a,G.op(g,b)), b.inverse()))\n",
    "        minimal = min(option1, option2, option3, option4)\n",
    "        if minimal == option1:\n",
    "            return (a, g, b)\n",
    "        if minimal == option2:\n",
    "            return (a.inverse(), G.op(a,g), b)\n",
    "        if minimal == option3:\n",
    "            return (a, G.op(g,b), b.inverse())\n",
    "        if minimal == option4:\n",
    "            return (a.inverse(), G.op(a,G.op(g,b)), b.inverse())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Square(%s, %s, %s)\" % (self.a, self.g, self.b)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Square):\n",
    "            return (self.a == other.a and self.b == other.b and self.g == other.g)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return (not self.__eq__(other))\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab92e4d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tensor Decoding <a name=\"tensor\"></a>\n",
    "\n",
    "Below we implement a simple tensor decoding algorithm. Given a word and two codes $C_A,C_B$, the algorithm alterates between decoding the rows according to $C_B$, and all columns according to $C_A$. This algorithm corrects up to $(d_1d_2-1)/4$ errors. \n",
    "\n",
    "Here, we adopt a slight improvement of this algorithm, as follows: \n",
    "1. Decode along all the rows. \n",
    "2. Alternate columns and rows repeatedly: we keep two sets called ``iterating_set_code_a`` and ``iterating_set_code_b``. Upon a correction of row $i$ (related to code $C_B$), each entry that was change signifies a column that needs to be checked (as it might not be in the code due to the change). Thus we'll add this column to ``iterating_set_code_b``. Iterating over ``iterating_set_code_b``, we do the same and update ``iterating_set_code_a``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba9021d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_decoding(tensor_word, C_A: LinearCode, C_B: LinearCode):\n",
    "    \"\"\" Returns a decoded word in tensor code. \n",
    "\n",
    "    Keyword arguments:\n",
    "    tensor_word -- matrix of length(C_A) x length(C_B).\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    \"\"\"\n",
    "\n",
    "    n_a = len(C_A.parity_check_matrix().columns())\n",
    "    n_b = len(C_B.parity_check_matrix().columns())\n",
    "    field = C_A.base_field()\n",
    "\n",
    "    def tensor_word_to_tuple(m):\n",
    "        return tuple(m.reshape((n_a * n_b)))\n",
    "\n",
    "    corrected_word = numpy.copy(tensor_word)\n",
    "    iterating_set_C_B = [i for i in range(n_a)]\n",
    "    iterating_set_C_A = [i for i in range(n_b)]\n",
    "    past_words = []\n",
    "    word_to_tuple = tensor_word_to_tuple(corrected_word)\n",
    "    while (len(iterating_set_C_A) != 0 or len(iterating_set_C_B) != 0) and word_to_tuple not in past_words:\n",
    "        past_words.append(word_to_tuple)\n",
    "\n",
    "        new_iterating_C_A = []\n",
    "        new_iterating_C_B = []\n",
    "        for i in iterating_set_C_B:\n",
    "            local_word = vector(field, corrected_word[i, :])\n",
    "            try:\n",
    "                corrected_locally = C_B.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_C_B.append(i)\n",
    "                continue\n",
    "            for j in range(n_b):\n",
    "                if local_word[j] != corrected_locally[j]:\n",
    "                    new_iterating_C_A.append(j)\n",
    "                corrected_word[i][j] = corrected_locally[j]\n",
    "        for j in iterating_set_C_A:\n",
    "            local_word = vector(field, corrected_word[:, j])\n",
    "            try:\n",
    "                corrected_locally = C_A.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_C_A.append(j)\n",
    "                continue\n",
    "            for i in range(n_a):\n",
    "                if local_word[i] != corrected_locally[i]:\n",
    "                    new_iterating_C_B.append(i)\n",
    "                corrected_word[i][j] = corrected_locally[i]\n",
    "        iterating_set_C_A = set(new_iterating_C_A)\n",
    "        iterating_set_C_B = set(new_iterating_C_B)\n",
    "        word_to_tuple = tensor_word_to_tuple(corrected_word)\n",
    "    return corrected_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d8641",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generating the parity check matrix of the code <a name=\"parity\"></a>\n",
    "\n",
    "The following function reterns a representation of the parity check matrix of $c^3LTC$ code. It gets a group $G$, two sets $A,B$ and two codes $C_A,C_B$, such that $n_A = |A|, n_B = |B|$ and $C_A,C_B$ are defined on the same field. \n",
    "\n",
    "The function proceeds in two stages:\n",
    "1. In the first stage, it collects the edges (by $A,B$) into sets.\n",
    "2. In the seocnd stage, the local constraint on each edge are injected according to the squares.\n",
    "    - Each edges \"sees\" a tuple of values squares such that the values on those squares \n",
    "      should be contained in either $C_A$ or $C_B$ (depending on whether it's an $A$-edge or $B$-edge).\n",
    "    - To enforce the condition above, each one of these squares is associated with a column from the\n",
    "      parity check of the local code ($C_A$ or $C_B$). The squares indicate the specific squares that\n",
    "      participate in the constraints on that edge. \n",
    "    - The dictionary (mapping) ''constraints'' in the code, holds a sparse representation of the constraints\n",
    "      in the parity check induced by the input parameters. It maps a square object (that indicates a column) \n",
    "      to a dictionary whose keys are row numbers and the values are the values in the large parity check matrix. \n",
    "    - In other words, a copy of the local parity check is being injected into the squares-parity-check\n",
    "      such that each column of the small parity check is placed into the column associated with different square\n",
    "      (according to the squares specified by the row). \n",
    "      \n",
    "The function returns a sparse representation of the parity check. It returns a dictionary (mapping) with ``Square`` elements as keys. Each square is mapped to a sparse representation of the corresponding column to this square in the parity check matrix. Namley, it contains a mapping from row number to value. Hence non zero values in the parity check matrix are specified first by their ``Square``, then by their row, and finally by their value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6091cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def embedding_local_parity_constraints_on_squares(C_A, C_B, G, A, B):\n",
    "    \"\"\" Returns\n",
    "    1) Sparse representation of the constrsints by a mapping of squares (represeted by 3 group elements (a,g,b))\n",
    "        to dictionary whose keys are rows in which the square has non zero value, and value is the value in the relevant row and column.\n",
    "    2) Number constraints of rows in the constraint matrix.\n",
    "\n",
    "    Keyword arguments:\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    G -- Sage group object.\n",
    "    A -- list of group elements.\n",
    "    B -- list of group elements.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    constraints = {}\n",
    "    row = 0\n",
    "    parity_A = C_A.parity_check_matrix()\n",
    "    parity_B = C_B.parity_check_matrix()\n",
    "    codim_C_A = len(parity_A.rows())\n",
    "    codim_C_B = len(parity_B.rows())\n",
    "\n",
    "    # Stage 1 - collecting the edges\n",
    "    edges_A = set()\n",
    "    edges_B = set()\n",
    "    for g in G:\n",
    "        for a in A:\n",
    "            edges_A.add(AEdge(G, a, g))\n",
    "        for b in B:\n",
    "            edges_B.add(BEdge(G, g, b))\n",
    "\n",
    "    assert len(edges_A) == len(list(G)) * len(A) / 2\n",
    "    assert len(edges_B) == len(list(G)) * len(B) / 2\n",
    "\n",
    "    # Stage 2 - iterating over edges and \"injecting\" constraints into squares\n",
    "    for e in edges_A:\n",
    "        a = e.a\n",
    "        g = e.g\n",
    "        for (j, b) in enumerate(B):  # B[j] = b\n",
    "            square = Square(G, a, g, b)\n",
    "            if square not in constraints:  # if no contraints were added on this square before\n",
    "                constraints[square] = {}\n",
    "            for (k, v) in enumerate(parity_A[:, j]):  # parity_A[k,j] = v\n",
    "                constraints[square][row + k] = v[0]  # v is represted as a length 1 array\n",
    "        row += codim_C_A\n",
    "\n",
    "    for e in edges_B:\n",
    "        g = e.g\n",
    "        b = e.b\n",
    "        for (i, a) in enumerate(A):  # A[i] = a\n",
    "            square = Square(G, a, g, b)\n",
    "            if square not in constraints:  # if no contraints were added on this square before\n",
    "                constraints[square] = {}\n",
    "            for (k, v) in enumerate(parity_B[:, i]):  # parity_B[k,i] = v\n",
    "                constraints[square][row + k] = v[0]  # v is represted as a length 1 array\n",
    "        row += codim_C_B\n",
    "\n",
    "    assert len(constraints) == len(A) * len(B) * len(list(G)) / 4\n",
    "    assert row == codim_C_A * len(edges_A) + codim_C_B * len(edges_B)\n",
    "\n",
    "    return (constraints, row, edges_A, edges_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c904a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Random generator sets <a name=\"sets\"></a>\n",
    "\n",
    "The following functions gets a group $G$, and two numbers, representing the size of two desired sets of generators. The number of elements of order 2 and of non order 2 are treated separatly (see the second and third argument to ``random_generators``).\n",
    "\n",
    "The function ``get_AB_with_TNC`` returns two sets $A,B$ that satisfies the total no-conjugacy:\n",
    "$$\n",
    "\\forall a\\in A, b\\in B, g\\in G, \\ g^{-1}ag\\ne b\n",
    "$$\n",
    "It searches for these sets for in a brute-force way for several trials and exists if no such pair was found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba58d0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def random_generators(G, n, n_order_2=0):\n",
    "    \"\"\" Returns an inverse closed set of n + n_order_2 elements from G.\n",
    "\n",
    "\n",
    "    Keyword arguments:\n",
    "    G -- Sage group object.\n",
    "    n -- number.\n",
    "    n_order_2 -- number of elements of order 2. \n",
    "    \n",
    "    Note:\n",
    "    1) n has to be smaller than the number of elements in G.\n",
    "    \"\"\"\n",
    "\n",
    "    list_G = list(G)\n",
    "    assert n < len(list_G)\n",
    "    gens = []\n",
    "    # non order 2 generators\n",
    "    i = 0\n",
    "    while i < n / 2:\n",
    "        c = random.choice(list_G)\n",
    "        if c not in gens and G.op(c, c) != G.identity():\n",
    "            gens.append(c)\n",
    "            gens.append(c.inverse())\n",
    "            i += 1\n",
    "    # order 2 generators\n",
    "    i = 0\n",
    "    while i < n_order_2:\n",
    "        c = random.choice(list_G)\n",
    "        if c not in gens and G.op(c, c) == G.identity():\n",
    "            gens.append(c)\n",
    "            i += 1    \n",
    "    return gens\n",
    "\n",
    "def get_AB_with_TNC(G, n, n_order_2 = 0, trials = 100):\n",
    "    \"\"\" Returns two sets of a group G of size n, for which that TNC condition hold.\n",
    "        If no sets were found after # of trials, it exits with error.  \n",
    "\n",
    "\n",
    "    Keyword arguments:\n",
    "    G -- Sage group object.\n",
    "    n -- number.\n",
    "    n_order_2 -- number. \n",
    "    trials -- number of trials to find A,B that uphold TNC. \n",
    "    \n",
    "    Note:\n",
    "    1) size has to be smaller than the number of elements in G.\n",
    "    \"\"\"\n",
    "    \n",
    "    for _ in range(trials):\n",
    "        A = random_generators(G,n,n_order_2)\n",
    "        B = random_generators(G,n,n_order_2)\n",
    "        violations = 0\n",
    "        for a in A:\n",
    "            for b in B:\n",
    "                for g in G:\n",
    "                    if G.op(a, g) == G.op(g, b):\n",
    "                        violations += 1\n",
    "                        break\n",
    "        if violations == 0:\n",
    "            return A, B\n",
    "    exit(1)\n",
    "\n",
    "def get_AB(G, n, n_order_2 = 0, trials = 100):\n",
    "    \"\"\" Returns two sets of a group G of size n, for which TNC condition does not necessarily hold.\n",
    "        If no sets were found after # of trials, it exits with error.  \n",
    "\n",
    "\n",
    "    Keyword arguments:\n",
    "    G -- Sage group object.\n",
    "    n -- number.\n",
    "    n_order_2 -- number. \n",
    "    trials -- number of trials to find A,B that uphold TNC. \n",
    "    \n",
    "    Note:\n",
    "    1) size has to be smaller than the number of elements in G.\n",
    "    \"\"\"\n",
    "    \n",
    "    sets_with_tnc = get_AB_with_TNC(G, n, n_order_2, trials)\n",
    "    if sets_with_tnc == None:\n",
    "        A = random_generators(G,n,n_order_2)\n",
    "        B = random_generators(G,n,n_order_2)\n",
    "        return A,B\n",
    "    else:\n",
    "        return sets_with_tnc\n",
    "    \n",
    "def get_AB_from_LPS(G,p,q):\n",
    "    \"\"\" Returns two sets of a group of size p + 1, according to the Lubotzky, Phillips and Sarnak construction of\n",
    "    Ramanujan Cayley graphs. \n",
    "\n",
    "\n",
    "    Keyword arguments:\n",
    "    G -- Sage group object.\n",
    "    p -- number.\n",
    "    q -- number. \n",
    "    \n",
    "    Note:\n",
    "    1) p,q = 1 mod 4 \n",
    "    2) Legendre symbol (q,p) = -1\n",
    "    \"\"\"\n",
    "    assert p % 4 == 1\n",
    "    assert q % 4 == 1\n",
    "    assert kronecker (q , p) == -1\n",
    "    F = IntegerModRing(q)\n",
    "    i = int(F(-1).square_root())\n",
    "    odd = [x for x in range(p) if int(x) % 2 != 0 and int(x) < p/2]\n",
    "    even = [x for x in range(-p,p) if int(x) % 2 == 0]\n",
    "    solutions = []\n",
    "    for a0 in odd:\n",
    "        for a1 in even:\n",
    "            for a2 in even:\n",
    "                for a3 in even:\n",
    "                    if (a0*a0 + a1*a1 + a2*a2 + a3*a3) == p:\n",
    "                        solutions.append((a0,a1,a2,a3))\n",
    "    generators = []\n",
    "    for s in solutions:\n",
    "        a0 = s[0]\n",
    "        a1 = s[1]\n",
    "        a2 = s[2]\n",
    "        a3 = s[3]\n",
    "        generators.append(G((matrix(F, 2,2,[[a0+i*a1, a2+i*a3],[-a2+i*a3,a0-i*a1]]))))\n",
    "\n",
    "    A = []\n",
    "    for g in generators:\n",
    "        A.append(g)\n",
    "        A.append(g.inverse())\n",
    "\n",
    "    random.shuffle(generators)\n",
    "    B = []\n",
    "    for g in generators:\n",
    "        B.append(g)\n",
    "        B.append(g.inverse())\n",
    "    return A,B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46daf9a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decoding c3LTC <a name=\"decoding\"></a>\n",
    "\n",
    "The decoding function ``decode_via_edges`` and ``decode_via_vertices`` decodes a word $w$. These functions different from the decoding algorithm presented in the original paper, and are conceptually similar to tensor decoding algorithm and expander code decoding. \n",
    "Similarly to algorithms for decoding in expander codes, ``decode_via_vertices`` decodes a word by locally correcting the local views of ''unsatisfied'' vertices (i.e., vertices whose local view is not a leagal tensor codeword). Similarly to decoding in tensor codes, ``decode_via_edges`` decodes the local view of ''unsatisfied'' edges (i.e., edges whose local view is not a leagal codeword in $C_A$ or $C_B$, depending on their type), and alternate between decoding all such ``AEdges`` followed by decoding of all ``BEdges`` (akin to the alternation between rows and columns in tensor decoding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21413db4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decode_via_edges(c3ltc, noisy_word):\n",
    "    squares_to_values = {}\n",
    "    for (i, v) in enumerate(noisy_word):\n",
    "        squares_to_values[c3ltc.index_to_square[i]] = v\n",
    "    init = True\n",
    "    iterating_set_A = None\n",
    "    iterating_set_B = None\n",
    "    past_words = []\n",
    "    word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "    while (init or (\n",
    "            len(iterating_set_A) != 0 or len(iterating_set_B) != 0)) and word_from_square_values not in past_words:\n",
    "        past_words.append(word_from_square_values)\n",
    "        if init:\n",
    "            init = False\n",
    "            iterating_set_A = set(c3ltc.edges_A)\n",
    "            iterating_set_B = set(c3ltc.edges_B)\n",
    "        new_iterating_set_A = set([])\n",
    "        new_iterating_set_B = set([])\n",
    "\n",
    "        for k,e in enumerate(iterating_set_A):\n",
    "            a = e.a\n",
    "            g = e.g\n",
    "            i = c3ltc.A.index(a)\n",
    "            local_word = vector(c3ltc.base_field, [0] * len(c3ltc.B))\n",
    "            for (j, b) in enumerate(c3ltc.B):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                local_word[j] = squares_to_values[square]\n",
    "            try:\n",
    "                corrected_localy = c3ltc.C_B.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_set_A.add(AEdge(c3ltc.G, a, g))\n",
    "                continue\n",
    "            for (j, b) in enumerate(c3ltc.B):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                if squares_to_values[square] != corrected_localy[j]:\n",
    "                    new_iterating_set_A.add(AEdge(c3ltc.G, a, G.op(g,b)))\n",
    "                    new_iterating_set_B.add(BEdge(c3ltc.G, g, b))\n",
    "                    new_iterating_set_B.add(BEdge(c3ltc.G, G.op(a,g), b))\n",
    "                squares_to_values[square] = corrected_localy[j]\n",
    "            if e in new_iterating_set_A:\n",
    "                new_iterating_set_A.remove(e)\n",
    "\n",
    "        for k,e in enumerate(iterating_set_B):\n",
    "            g = e.g\n",
    "            b = e.b\n",
    "            j = c3ltc.B.index(b)\n",
    "            local_word = vector(c3ltc.base_field, [0] * len(c3ltc.A))\n",
    "            for (i, a) in enumerate(c3ltc.A):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                local_word[i] = squares_to_values[square]\n",
    "            try:\n",
    "                corrected_localy = c3ltc.C_A.decode_to_code(local_word)\n",
    "            except:\n",
    "                new_iterating_set_B.add(BEdge(c3ltc.G, g, b))\n",
    "                continue\n",
    "            for (i, a) in enumerate(c3ltc.A):\n",
    "                square = Square(c3ltc.G,a, g, b)\n",
    "                if squares_to_values[square] != corrected_localy[i]:\n",
    "                    new_iterating_set_B.add(BEdge(c3ltc.G, G.op(a,g), b))\n",
    "                    new_iterating_set_A.add(AEdge(c3ltc.G, a, g))\n",
    "                    new_iterating_set_A.add(AEdge(c3ltc.G, a, G.op(g,b)))\n",
    "                squares_to_values[square] = corrected_localy[i]\n",
    "            if e in new_iterating_set_B:\n",
    "                new_iterating_set_B.remove(e)\n",
    "\n",
    "        iterating_set_A = new_iterating_set_A\n",
    "        iterating_set_B = new_iterating_set_B\n",
    "        word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "    return word_from_square_values\n",
    "\n",
    "def decode_via_vertices(c3ltc, noisy_word):\n",
    "    n_a = len(c3ltc.C_A.parity_check_matrix().columns())\n",
    "    n_b = len(c3ltc.C_B.parity_check_matrix().columns())\n",
    "    M = MatrixSpace(c3ltc.base_field, n_a, n_b)\n",
    "    squares_to_values = {}\n",
    "    for (i, v) in enumerate(noisy_word):\n",
    "        squares_to_values[c3ltc.index_to_square[i]] = v\n",
    "    init = True\n",
    "    iterating_set = None\n",
    "    past_words = []\n",
    "    word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "    M = MatrixSpace(c3ltc.base_field, n_a, n_b)\n",
    "    while (init or len(iterating_set)) != 0 and word_from_square_values not in past_words:\n",
    "        past_words.append(word_from_square_values)\n",
    "        if init:\n",
    "            init = False\n",
    "            iterating_set = set(c3ltc.G)\n",
    "        new_iterating_set = set([])\n",
    "        for g in iterating_set:\n",
    "            local_view = M(matrix(n_a, n_b))\n",
    "            for i, a in enumerate(c3ltc.A):\n",
    "                for j, b in enumerate(c3ltc.B):\n",
    "                    square = Square(c3ltc.G,a, g, b)\n",
    "                    local_view[i,j] = squares_to_values[square]\n",
    "            try:\n",
    "                corrected_local_view = tensor_decoding(M(local_view), c3ltc.C_A, c3ltc.C_B)\n",
    "            except:\n",
    "                new_iterating_set.append(g)\n",
    "                continue\n",
    "            for i, a in enumerate(c3ltc.A):\n",
    "                for j, b in enumerate(c3ltc.B):\n",
    "                    square = Square(c3ltc.G,a, g, b)\n",
    "                    if corrected_local_view[i][j] != local_view[i][j]:\n",
    "                        new_iterating_set.add(G.op(a,g))\n",
    "                        new_iterating_set.add(G.op(g,b))\n",
    "                        new_iterating_set.add(G.op(a,G.op(g,b)))\n",
    "                    squares_to_values[square] = corrected_local_view[i][j]\n",
    "            if g in new_iterating_set:\n",
    "                new_iterating_set.remove(g)\n",
    "        iterating_set = new_iterating_set\n",
    "        word_from_square_values = c3ltc.square_to_value_to_word(squares_to_values)\n",
    "\n",
    "    return word_from_square_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121aa7b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# c3LTC object <a name=\"c3ltc\"></a>\n",
    "\n",
    "The class ``c3LTC`` generates an object of the new code. It receives two codes, $C_A,C_B$ a group $G$ and two generator sets $A,B$. The code generates parity check and generator matrices using the function ``embedding_local_parity_constraints_on_squares``. It also uses the library [spasm](https://github.com/cbouilla/spasm). to perform linear algebra functions, for performance improvements. \n",
    "\n",
    "The function ``local_codeword_on_vertex`` gets as input a word $w$ (possibly noisy) and a vertex $v$. It returns $w|_{X(v)}$, the restriction of $w$ to the squares $v$ sees in his local tensor-word view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a095e82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class c3LTC:\n",
    "\n",
    "    def __init__(self, C_A, C_B, G, A, B):\n",
    "        assert len(C_A.generator_matrix().columns()) == len(A)\n",
    "        assert len(C_B.generator_matrix().columns()) == len(B)\n",
    "        assert C_A.base_field().characteristic() == C_B.base_field().characteristic()\n",
    "\n",
    "        (sparse_constraints, count, self.edges_A, self.edges_B) = embedding_local_parity_constraints_on_squares(C_A, C_B, G, A, B)\n",
    "\n",
    "        self.square_to_index = {}\n",
    "        self.index_to_square = {}\n",
    "        self.squares = list(sparse_constraints)\n",
    "        self.vertex_to_squares = {}\n",
    "        self.vertex_to_neighbours_A = {}\n",
    "        self.vertex_to_neighbours_B = {}\n",
    "        self.square_to_vertices = {}\n",
    "        self.n_vertices = len(list(G))\n",
    "\n",
    "        list_G = list(G)\n",
    "\n",
    "        for (i, l) in enumerate(self.squares):\n",
    "            self.square_to_index[l] = i\n",
    "            self.index_to_square[i] = l\n",
    "        \n",
    "        \n",
    "        for g in G:\n",
    "            view = numpy.zeros((len(A), len(B)))\n",
    "            for (i, a) in enumerate(A):\n",
    "                for (j, b) in enumerate(B):\n",
    "                    view[i][j] = self.squares.index(Square(G,a, g, b))\n",
    "            self.vertex_to_squares[list_G.index(g)] = view\n",
    "\n",
    "        for g in G:\n",
    "            view = []\n",
    "            for (i, a) in enumerate(A):\n",
    "                view.append(list_G.index(G.op(a,g)))\n",
    "            self.vertex_to_neighbours_A[list_G.index(g)] = view\n",
    "        \n",
    "        for g in G:\n",
    "            view = []\n",
    "            for (j, b) in enumerate(B):\n",
    "                view.append(list_G.index(G.op(g,b)))\n",
    "            self.vertex_to_neighbours_B[list_G.index(g)] = view\n",
    "        \n",
    "        for (i, s) in enumerate(self.squares):\n",
    "            view = []\n",
    "            a = s.a\n",
    "            g = s.g\n",
    "            b = s.b\n",
    "            view.append(int(list_G.index(g)))\n",
    "            view.append(int(list_G.index(G.op(a,g))))\n",
    "            view.append(int(list_G.index(G.op(a,G.op(g,b)))))\n",
    "            view.append(int(list_G.index(G.op(g,b))))\n",
    "            self.square_to_vertices[i] = view\n",
    "\n",
    "        # properties of the code\n",
    "\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.C_A = C_A\n",
    "        self.C_B = C_B\n",
    "        self.G = G\n",
    "        self.base_field = C_A.base_field()\n",
    "        if len(self.base_field) == self.base_field.characteristic():\n",
    "            # process sparse constraints\n",
    "            parity_constraints = numpy.zeros((count, len(sparse_constraints)))\n",
    "            for (i, l) in enumerate(sparse_constraints):\n",
    "                for k in sparse_constraints[l]:\n",
    "                    parity_constraints[k][i] = sparse_constraints[l][k]\n",
    "\n",
    "            # additional mappings\n",
    "            self.parity_constraints = parity_constraints\n",
    "            \n",
    "            gen, par = row_reduce_and_orthogonal(sparse_constraints, C_A.base_field().characteristic(), count,len(sparse_constraints))\n",
    "            M = MatrixSpace(self.base_field, gen.shape[0],\n",
    "                            gen.shape[1])\n",
    "            self.generator_matrix = M(gen)\n",
    "            M = MatrixSpace(self.base_field, par.shape[0],\n",
    "                            par.shape[1])\n",
    "            self.parity_check_matrix = M(par)\n",
    "            self.length = numpy.array(self.generator_matrix).shape[1]\n",
    "            self.dimension = numpy.array(self.generator_matrix).shape[0]\n",
    "            print(\"Generated c3LTC code with dimension \" + str(self.dimension) + \" and length \" + str(self.length) + \" and rate: \" + str(self.dimension/self.length))\n",
    "        else:\n",
    "            M = MatrixSpace(self.base_field, count, len(sparse_constraints))\n",
    "\n",
    "            # process sparse constraints\n",
    "            parity_constraints = M(matrix(count, len(sparse_constraints)))\n",
    "            for (i, l) in enumerate(sparse_constraints):\n",
    "                for k in sparse_constraints[l]:\n",
    "                    parity_constraints[k,i] = sparse_constraints[l][k]\n",
    "\n",
    "            # additional mappings\n",
    "            self.parity_constraints = parity_constraints\n",
    "            \n",
    "            C = codes.LinearCode(M(parity_constraints))\n",
    "            self.generator_matrix = C.parity_check_matrix()\n",
    "            self.parity_check = C.generator_matrix()\n",
    "            self.length = numpy.array(self.generator_matrix).shape[1]\n",
    "            self.dimension = numpy.array(self.generator_matrix).shape[0]\n",
    "            print(\"Generated c3LTC code with dimension \" + str(self.dimension) + \" and length \" + str(self.length) + \" and rate: \" + str(self.dimension/self.length))\n",
    "            \n",
    "    def square_to_value_to_word(self, squares_to_values):\n",
    "        corrected_word = vector(self.base_field, [0] * len(squares_to_values))\n",
    "        for square in self.square_to_index:\n",
    "            corrected_word[self.square_to_index[square]] = squares_to_values[square]\n",
    "        return corrected_word\n",
    "\n",
    "    def syndrome(self, c):\n",
    "        return self.parity_check_matrix * c\n",
    "    \n",
    "    def decode_via_edges(self, noisy_word):\n",
    "        return decode_via_edges(self, noisy_word)\n",
    "    \n",
    "    def decode_via_vertices(self, noisy_word):\n",
    "        return decode_via_vertices(self, noisy_word)\n",
    "\n",
    "    def local_codeword_on_vertex(self, vertex, word):\n",
    "        square_view = self.vertex_to_squares[vertex]\n",
    "        rows = len(square_view)\n",
    "        cols = len(square_view[0])\n",
    "        M = MatrixSpace(self.base_field, rows, cols)\n",
    "        local_view_values = M(matrix(rows, cols))\n",
    "        \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                local_view_values[i,j] = word[int(self.vertex_to_squares[vertex][i][j])]\n",
    "        return local_view_values\n",
    "\n",
    "    def __repr__(self):\n",
    "        rep = 'c3LTC'\n",
    "        return rep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9bb067",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Concrete Example <a name=\"example\"></a>\n",
    "\n",
    "Below is a concrete example for a construction of the new code with the following parameters:\n",
    "\n",
    "- $G = PSL(2,7)$. \n",
    "- $C_A,C_B = RS[4,6]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee89fef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Start row reduce from c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IO] loading 1512 x 2016 SMS matrix modulo 7... 12.1k NNZ [0.0s]\n",
      "[CSR] Compressing... 12096 actual NZ, Mem usage = 102.8kbyte [0.00s]\n",
      "LU : 1354 / 2016 [|L| = 0 / |U| = 190248] -- current density= (0.447 vs 0.112) --- rank >= 1343LU : 1374 / 2016 [|L| = 0 / |U| = 190248] -- current density= (0.549 vs 0.112) --- rank >= 1343\n",
      "[LU] testing for early abort...SUCCESS\n",
      "\n",
      "LU : 167 / 168 [|L| = 0 / |U| = 223856] -- current density= (0.998 vs 0.890) --- rank >= 167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Actual time in c 1.767413854598999\n",
      "[*] Finished row reduce from c\n",
      "Generated c3LTC code with dimension 168 and length 1512 and rate: 0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "G = PSL(2,7)\n",
    "G.op = lambda a,b: a * b \n",
    "A, B = get_AB(G, 6)\n",
    "C_A = ReedSolomonCode(GF(7), Integer(6), Integer(4))\n",
    "C_B = ReedSolomonCode(GF(7), Integer(6), Integer(4))\n",
    "c3ltc = c3LTC(C_A, C_B, G, A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd474955",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = PSL(2,7)\n",
    "G.op = lambda a,b: a * b \n",
    "A, B = get_AB(G, 6)\n",
    "n = 6\n",
    "k = 4\n",
    "F = GF(3^3)\n",
    "M = codes.GeneralizedReedSolomonCode(F.list()[:n], k).generator_matrix()\n",
    "C_A = codes.LinearCode(M)\n",
    "C_B = codes.LinearCode(M)\n",
    "c3ltc = c3LTC(C_A, C_B, G, A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231284e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vertices that participate in square no. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda26f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_square(c3ltc,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3918a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Squares touching $v$. \n",
    "\n",
    "The numbers in the blue column are the $A$-neighbors of $v$.\n",
    "The numbers in the red row are the $B$-neighbors of $v$.\n",
    "Within the table, the entries correspond to the squares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9791c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "local_view(c3ltc,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5fe06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Shows the squares of the local view of vertices $v_1,v_2$ (the common row is highlighted). \n",
    "\n",
    "The generating sets $A,B$ of the Cayley graph is ordered like: $(a_1,a_1^{-1}, a_2,a_2^{-1}...)$. That is, the generators are ordered in pairs of generator followed by its inverse. (There are no $a_i = a_i^{-1}$). Similarly for the $b$'s.\n",
    "\n",
    "Therefore, if $v_2 = a_1 \\cdot  v_1$ then in the local view of $v_2$, the second neighbour is going to be $v_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bd2b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_common(c3ltc, 1, c3ltc.vertex_to_neighbours_A[1][0], \"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4f393",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Encoding, Decoding and Testing <a name=\"tests\"></a>\n",
    "\n",
    "Below we provide several functions for encoding, decoding, and testing the properties of the generated code, as well as some supllementry functions. \n",
    "\n",
    "The functions are as follows:\n",
    "- ``word_with_k_injected_local_views`` - Create a random word with k local views \"injected\" with random tensor codewords. \n",
    "- ``is_word_in_tensor_code`` - Checks if a matrix tensor word is in code generated two codes $C_A,C_B$.\n",
    "- ``unsatisfied_vertices`` - Returns a list of vertices for which the local view in the given word is not in the tensor code. \n",
    "- ``estimate_ltc_constant_with_injected_local_views`` - Returns an estimation of the local testability parameter by sampling a random noisy word and counting the relative fraction of unsatisfied vertices. \n",
    "- ``estimate_ltc_constant_with_random_local_views`` - Returns an estimation of the local testability parameter by sampling a random noisy word and counting the relative fraction of unsatisfied vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa429f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_non_zero(vec, field):\n",
    "    count = 0\n",
    "    for e in vec:\n",
    "        if e != field(0):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def word_with_k_injected_local_views(c3ltc, k):\n",
    "    \"\"\" Create a random word with k local views \"injected\" with random tensor codewords. \n",
    "        Note that some vertices may not have a tensor codeword in their local view because the \n",
    "        function writes over pre-existing values. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    k -- number. \n",
    "    \"\"\"\n",
    "    word = vector(c3ltc.base_field, [0] * c3ltc.length)\n",
    "    for _ in range(k):\n",
    "        v = random.randint(0,len(c3ltc.G)-1)\n",
    "        local_view_flat = c3ltc.vertex_to_squares[v].reshape((C_A.length() * C_B.length()))\n",
    "        random_local_word = random_tensor_word(c3ltc.C_A, c3ltc.C_B)\n",
    "        for (i,b) in enumerate(random_local_word):\n",
    "            word[int(local_view_flat[i])] = b\n",
    "    return word\n",
    "\n",
    "def is_word_in_tensor_code(C_A,C_B, word):\n",
    "    \"\"\" Checks if a matrix tensor word is in code by verifying that each row and column are \n",
    "        in the associated code. \n",
    "\n",
    "    Keyword arguments:\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    word -- number. \n",
    "    \"\"\"\n",
    "    rows = word.dimensions()[0]\n",
    "    cols = word.dimensions()[1]\n",
    "    field = C_A.base_field()\n",
    "    for i in range(rows):\n",
    "        row = word[i,:]\n",
    "        if 0 != count_non_zero(C_A.syndrome(vector(row)),field):\n",
    "            return false\n",
    "    for i in range(cols):\n",
    "        col = word[:,i]\n",
    "        if 0 != count_non_zero(C_B.syndrome(vector(col)),field):\n",
    "            return false\n",
    "    return true\n",
    "\n",
    "def unsatisfied_vertices(c3ltc, word):\n",
    "    \"\"\" Returns a list of vertices for which the local view in the given word is not in the\n",
    "        tensor code. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    word -- number. \n",
    "    \"\"\"\n",
    "    n_vertices = len(c3ltc.G)\n",
    "    unsat = []\n",
    "    for g in range(n_vertices):\n",
    "        lv = c3ltc.local_codeword_on_vertex(g, word)\n",
    "        if not is_word_in_tensor_code(c3ltc.C_A,c3ltc.C_B, lv):\n",
    "            unsat.append(g)\n",
    "    return unsat\n",
    "\n",
    "\n",
    "def estimate_ltc_constant_with_injected_local_views(c3ltc, trials = 10, max_injected = 50):\n",
    "    \"\"\" Returns an estimation of the local testability parameter by sampling a random noisy word and counting the \n",
    "        relative fraction of unsatisfied vertices. \n",
    "        The noise is generated by injecting random tensor words into the local view of vertices. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    trials -- number. \n",
    "    max_injected -- number. \n",
    "    \"\"\"\n",
    "    c = Infinity\n",
    "    n_vertices = len(c3ltc.G)\n",
    "    for _ in range(trials):\n",
    "        word = word_with_k_injected_local_views(c3ltc, max_injected)\n",
    "        syndrome_weight = float(\n",
    "            len(unsatisfied_vertices(c3ltc,word)) / n_vertices\n",
    "        )\n",
    "        error_weight = float(numpy.count_nonzero(word)/ c3ltc.length)\n",
    "        if error_weight != 0:\n",
    "            c = min(c, float(syndrome_weight / error_weight))\n",
    "    return c\n",
    "\n",
    "def estimate_ltc_constant_with_random_local_views(c3ltc, trials = 10, max_injected = 50, sparsity = 2):\n",
    "    \"\"\" Returns an estimation of the local testability parameter by sampling a random noisy word and counting the \n",
    "        relative fraction of unsatisfied vertices. \n",
    "        The noise is sampled randomly. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    trials -- number. \n",
    "    max_injected -- number. \n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    c = Infinity\n",
    "    n_vertices = len(c3ltc.G)\n",
    "    for _ in range(trials):\n",
    "        noisy_word, word = random_noisy_word(c3ltc, sparsity)\n",
    "        syndrome_weight = float(\n",
    "            len(unsatisfied_vertices(c3ltc,noisy_word)) / n_vertices\n",
    "        )\n",
    "        error_weight = float(numpy.count_nonzero(word - noisy_word)/ c3ltc.length)\n",
    "        if error_weight != 0:\n",
    "            c = min(c, float(syndrome_weight / error_weight))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40f56f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Functions for random samplings (used in the functions above).\n",
    "\n",
    "- ``random_vector`` - Retruns a random vector of a specified size, each entry sampled in the range between 0 and max_val.\n",
    "- ``random_tensor_word`` - Retruns a random tensor codeword. It is achieved by sampling a random vector, multiplying it by the tensor of the generators matrices of $C_A, C_B$.\n",
    "- ``random_noisy_word`` - Retruns a noisy c3ltc codeword by encoding a random vector. \n",
    "- ``random_word`` - Retruns a c3ltc codeword by encoding a random vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842938c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def random_vector(size, field, sparsity = 2):\n",
    "    \"\"\" Retruns a random vector of a specified size, each entry sampled in the range between \n",
    "        0 and max_val. Sparsity reflects that a non-zero probability is sampled.\n",
    "        The probability of a non-zero element to appear in the array is 1/(max_val - 1) * (1/2) ^ sparsity.\n",
    "\n",
    "    Keyword arguments:\n",
    "    size -- number.\n",
    "    max_val -- number.\n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    return vector([field.random_element() if numpy.random.binomial(1, pow(0.5,sparsity), 1)[0] else field(0) for _ in range(size)])\n",
    "\n",
    "def random_tensor_word(C_A, C_B):\n",
    "    \"\"\" Retruns a random tensor codeword. It is achieved by sampling a random vector, multiplying\n",
    "        it by the tensor of the generators matrices of C_A, C_B.\n",
    "        The word returned is a flattening of the \"matrix\" view of the tensor codeword into a\n",
    "        single vector by concatenating the rows of the respective matrix.\n",
    "        Sparsity parameter is defined in the random_vector function. \n",
    "\n",
    "    Keyword arguments:\n",
    "    C_A -- Sage code object.\n",
    "    C_B -- Sage code object.\n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    tensor_dimension = C_A.dimension() * C_B.dimension()\n",
    "    rv = random_vector(tensor_dimension,C_A.base_field(),0)\n",
    "    message = vector(C_A.base_field(), rv)\n",
    "    return (C_A.generator_matrix().tensor_product(C_B.generator_matrix()).transpose() * message)\n",
    "\n",
    "def random_noisy_word(c3ltc, sparsity = 2):\n",
    "    \"\"\" Retruns a noisy c3ltc codeword by encoding a random vector. \n",
    "    Sparsity parameter is defined in the random_vector function. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    sparsity -- number. \n",
    "    \"\"\"\n",
    "    field = c3ltc.base_field\n",
    "    error = vector(field, random_vector(c3ltc.length, field,sparsity))\n",
    "    word = vector(field, random_word(c3ltc)) \n",
    "    return vector(field, word + error), vector(field, word)\n",
    "\n",
    "def random_word(c3ltc):\n",
    "    \"\"\" Retruns a c3ltc codeword by encoding a random vector. \n",
    "\n",
    "    Keyword arguments:\n",
    "    c3ltc -- c3LTC object.\n",
    "    \"\"\"\n",
    "    field = c3ltc.base_field\n",
    "    rv = random_vector(c3ltc.dimension,field,0)\n",
    "    message = c3ltc.generator_matrix.transpose() * vector(field, rv)    \n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8da2a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below we test the decoding algorithms on a noisy codeword, generated by adding random noise a codeword. First, we apply decoding along the edges, then decoding along the vertices. After each run, we print whether the decoding was succesful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb685fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_word, word = random_noisy_word(c3ltc,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1263cb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corrected = c3ltc.decode_via_edges(noisy_word)\n",
    "print(\"Decoded correctly by edges?\", corrected == word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c38d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = c3ltc.decode_via_vertices(noisy_word)\n",
    "print(\"Decoded correctly by vertices?\", corrected == word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33201267",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below we print a heuristic estimation of the generated code. See the functions ``estimate_ltc_constant_with_injected_local_views`` and ``estimate_ltc_constant_with_random_local_views``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LTC constant, structured noise\", estimate_ltc_constant_with_injected_local_views(c3ltc))\n",
    "print(\"LTC constant, random noise\", estimate_ltc_constant_with_random_local_views(c3ltc, sparsity = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f41dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.7",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
